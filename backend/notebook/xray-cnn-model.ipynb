{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3324348,"sourceType":"datasetVersion","datasetId":576013},{"sourceId":709906,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":539265,"modelId":552490}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\n# 1. Preprocessing\ntransform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])  # grayscale\n])\n\n# 2. Load dataset\ndataset = datasets.ImageFolder(root=\"/kaggle/input/covid19-radiography-database/COVID-19_Radiography_Dataset\",\n                               transform=transform)\n\n# 3. Create DataLoader\nloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\n# 4. Check classes\nprint(dataset.classes)\n# Output: ['COVID', 'Lung_Opacity', 'Normal', 'Viral_Pneumonia']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:48:29.040547Z","iopub.execute_input":"2026-01-04T12:48:29.041014Z","iopub.status.idle":"2026-01-04T12:49:45.600820Z","shell.execute_reply.started":"2026-01-04T12:48:29.040989Z","shell.execute_reply":"2026-01-04T12:49:45.599988Z"}},"outputs":[{"name":"stdout","text":"['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia']\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\nimport timm  # for EfficientNet\nfrom sklearn.metrics import classification_report, confusion_matrix\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:51:30.462566Z","iopub.execute_input":"2026-01-04T12:51:30.463255Z","iopub.status.idle":"2026-01-04T12:51:30.467224Z","shell.execute_reply.started":"2026-01-04T12:51:30.463230Z","shell.execute_reply":"2026-01-04T12:51:30.466485Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Transformations (data augmentation + normalization)\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),        # EfficientNet input size\n    transforms.RandomHorizontalFlip(),    # Augmentation\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])   # X-rays are grayscale\n])\n\n# Dataset path\ndata_dir = \"/kaggle/input/covid19-radiography-database/COVID-19_Radiography_Dataset\"  # replace with your path\n\n# Load dataset\ndataset = datasets.ImageFolder(root=data_dir, transform=transform)\n\n# Train / validation split\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n# Check classes\nprint(dataset.classes)\n# ['COVID', 'Lung_Opacity', 'Normal', 'Viral_Pneumonia']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:52:12.486746Z","iopub.execute_input":"2026-01-04T12:52:12.487360Z","iopub.status.idle":"2026-01-04T12:52:27.754665Z","shell.execute_reply.started":"2026-01-04T12:52:12.487337Z","shell.execute_reply":"2026-01-04T12:52:27.753912Z"}},"outputs":[{"name":"stdout","text":"['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia']\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Load pretrained EfficientNet (B0) from timm\nmodel = timm.create_model('efficientnet_b0', pretrained=True)\n\n# Modify classifier for 4 classes\nnum_features = model.classifier.in_features\nmodel.classifier = nn.Sequential(\n    nn.Linear(num_features, 256),\n    nn.ReLU(),\n    nn.Dropout(0.4),\n    nn.Linear(256, 4)  # 4 classes\n)\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:52:29.928582Z","iopub.execute_input":"2026-01-04T12:52:29.929100Z","iopub.status.idle":"2026-01-04T12:52:31.393744Z","shell.execute_reply.started":"2026-01-04T12:52:29.929079Z","shell.execute_reply":"2026-01-04T12:52:31.393139Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/21.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df00188096734fffa159d16d06115656"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:52:43.296089Z","iopub.execute_input":"2026-01-04T12:52:43.296861Z","iopub.status.idle":"2026-01-04T12:52:43.301789Z","shell.execute_reply.started":"2026-01-04T12:52:43.296837Z","shell.execute_reply":"2026-01-04T12:52:43.301020Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"epochs = 10  # you can increase later\n\nfor epoch in range(epochs):\n    model.train()\n    running_loss = 0\n    correct = 0\n    total = 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    train_acc = 100 * correct / total\n    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:52:50.738870Z","iopub.execute_input":"2026-01-04T12:52:50.739166Z","iopub.status.idle":"2026-01-04T13:37:09.062805Z","shell.execute_reply.started":"2026-01-04T12:52:50.739145Z","shell.execute_reply":"2026-01-04T13:37:09.062025Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10], Loss: 0.5572, Train Acc: 78.69%\nEpoch [2/10], Loss: 0.4197, Train Acc: 83.92%\nEpoch [3/10], Loss: 0.3911, Train Acc: 85.08%\nEpoch [4/10], Loss: 0.3630, Train Acc: 86.06%\nEpoch [5/10], Loss: 0.3460, Train Acc: 86.61%\nEpoch [6/10], Loss: 0.3290, Train Acc: 87.17%\nEpoch [7/10], Loss: 0.3135, Train Acc: 88.06%\nEpoch [8/10], Loss: 0.3017, Train Acc: 88.33%\nEpoch [9/10], Loss: 0.2880, Train Acc: 88.89%\nEpoch [10/10], Loss: 0.2754, Train Acc: 89.20%\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"model.eval()\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, preds = torch.max(outputs, 1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\nprint(\"Classification Report:\\n\")\nprint(classification_report(all_labels, all_preds, target_names=dataset.classes))\n\nprint(\"Confusion Matrix:\\n\")\nprint(confusion_matrix(all_labels, all_preds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:43:25.791538Z","iopub.execute_input":"2026-01-04T13:43:25.791848Z","iopub.status.idle":"2026-01-04T13:44:45.500284Z","shell.execute_reply.started":"2026-01-04T13:43:25.791828Z","shell.execute_reply":"2026-01-04T13:44:45.499434Z"}},"outputs":[{"name":"stdout","text":"Classification Report:\n\n                 precision    recall  f1-score   support\n\n          COVID       0.86      0.75      0.80      1465\n   Lung_Opacity       0.84      0.84      0.84      2382\n         Normal       0.88      0.92      0.90      4087\nViral Pneumonia       0.94      0.94      0.94       532\n\n       accuracy                           0.87      8466\n      macro avg       0.88      0.86      0.87      8466\n   weighted avg       0.87      0.87      0.87      8466\n\nConfusion Matrix:\n\n[[1095  169  200    1]\n [  84 2008  285    5]\n [  91  205 3763   28]\n [   3    6   21  502]]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"torch.save(model.state_dict(), \"efficientnet_xray.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:46:20.963368Z","iopub.execute_input":"2026-01-04T13:46:20.963843Z","iopub.status.idle":"2026-01-04T13:46:21.018653Z","shell.execute_reply.started":"2026-01-04T13:46:20.963820Z","shell.execute_reply":"2026-01-04T13:46:21.018080Z"}},"outputs":[],"execution_count":12}]}